import datetime
import json
import time
import asyncio
import threading
import random  # –î–æ–±–∞–≤—å—Ç–µ –∏–º–ø–æ—Ä—Ç –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
from typing import Dict, Any, List, Optional, Tuple
from supabase import create_client, Client
from config import SUPABASE_URL, SUPABASE_KEY
import sys

# –í –Ω–∞—á–∞–ª–µ database.py –¥–æ–±–∞–≤–∏–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –∫–æ–¥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤
print(f"Loading database.py with id: {id(sys.modules['__main__'] if '__main__' in sys.modules else 0)}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫—ç—à–∏
_formatted_data_cache = {}  # –ö—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Supabase –∫–ª–∏–µ–Ω—Ç–∞
try:
    # –ü—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ –æ–±—ã—á–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except TypeError as e:
    if 'proxy' in str(e):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±, –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º proxy
        from supabase._sync.client import SyncClient
        options = {}  # –ë–∞–∑–æ–≤—ã–µ –æ–ø—Ü–∏–∏ –±–µ–∑ proxy
        supabase = SyncClient(SUPABASE_URL, SUPABASE_KEY, options)
    else:
        raise e

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—ç—à–∞
_cache_update_lock = threading.Lock()
_cache_updating = False

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
_last_cache_update_time = 0

# –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∫—ç—à–∞
_format_cache_lock = asyncio.Lock()

# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∫—ç—à–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–≤–æ–π–Ω—É—é –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
class CacheData:
    def __init__(self, name="Unnamed"):
        self.name = name  # –ò–º—è –∫—ç—à–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.data = None  # –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.timestamp = 0  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        self._new_data = None  # –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–æ –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        self._update_lock = asyncio.Lock()  # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    
    async def update(self, data_fetcher):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫—ç—à, –∏—Å–ø–æ–ª—å–∑—É—è –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        if self._update_lock.locked():
            print(f"[CACHE] {self.name} cache update already in progress, skipping")
            return False  # –£–∂–µ –∏–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        
        async with self._update_lock:
            try:
                start_time = time.time()
                print(f"[CACHE] Starting update for {self.name} cache")
                
                # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                self._new_data = await data_fetcher()
                
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ, –æ–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫—ç—à
                if self._new_data is not None:
                    self.data = self._new_data
                    self.timestamp = time.time()
                    data_size = len(self._new_data) if hasattr(self._new_data, '__len__') else "N/A"
                    self._new_data = None
                    
                    elapsed = time.time() - start_time
                    print(f"[CACHE] {self.name} cache updated successfully in {elapsed:.2f}s - size: {data_size}")
                    return True
                    
                print(f"[CACHE] {self.name} cache update failed - no data received")
                return False
            except Exception as e:
                print(f"[CACHE] Error updating {self.name} cache: {e}")
                return False
    
    def get(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞"""
        return self.data
    
    def is_valid(self, ttl=900):  # —É–≤–µ–ª–∏—á–∏–º –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –¥–æ 15 –º–∏–Ω—É—Ç
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–∫—Ç—É–∞–ª–µ–Ω –ª–∏ –∫—ç—à"""
        return self.data is not None and (time.time() - self.timestamp) < ttl

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–µ–π –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
full_apy_cache = CacheData("Full APY")   # –ö—ç—à –¥–ª—è –≤—Å–µ—Ö APY –¥–∞–Ω–Ω—ã—Ö
top_apy_cache = CacheData("Top APY")    # –ö—ç—à –¥–ª—è top-1 APY
top_three_cache = CacheData("Top Three APY")  # –ö—ç—à –¥–ª—è top-3 APY
top_ten_cache = CacheData("Top Ten APY")    # –ö—ç—à –¥–ª—è top-10 APY
assets_cache = CacheData("Assets")     # –ö—ç—à –¥–ª—è —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–æ–≤
chains_cache = CacheData("Chains")     # –ö—ç—à –¥–ª—è —Å–ø–∏—Å–∫–∞ –±–ª–æ–∫—á–µ–π–Ω–æ–≤

def log_query(operation, user_id=None, username=None, verbose=False):
    """Log database queries with configurable verbosity"""
    if not verbose:
        return  # –í—ã—Ö–æ–¥–∏–º –±–µ–∑ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã
    
    timestamp = datetime.datetime.now().isoformat()
    user_info = f"[USER:{user_id}|{username}]" if user_id else ""
    print(f"[{timestamp}] {user_info} DB Action: {operation}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ—à–∏–±–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ Supabase
def has_error(response):
    """Check if Supabase response contains an error"""
    if hasattr(response, 'error'):
        return response.error
    # –î–ª—è –≤–µ—Ä—Å–∏–∏ API, –≥–¥–µ –Ω–µ—Ç —Å–≤–æ–π—Å—Ç–≤–∞ error
    if hasattr(response, 'data') and isinstance(response.data, dict) and 'error' in response.data:
        return response.data['error']
    return None

async def _fetch_latest_full_apy():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö APY –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    try:
        # –í—ã–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–Ω—É—é RPC —Ñ—É–Ω–∫—Ü–∏—é —Å –ø—É—Å—Ç—ã–º —Å–ª–æ–≤–∞—Ä–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        response = supabase.rpc('get_latest_apy_data', {}).execute()
        
        if has_error(response):
            print(f"Error calling get_latest_apy_data: {response.error}")
            return None
        
        result = response.data if response.data else []
        
        # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: –∏–∑–≤–ª–µ–∫–∞–µ–º project –∏–∑ pool_id
        for item in result:
            if 'pool_id' in item and item['pool_id']:
                parts = item['pool_id'].split('_')
                if len(parts) >= 3:
                    item['project'] = '_'.join(parts[2:])
                else:
                    item['project'] = parts[0] if parts else ''
        
        return result
    except Exception as e:
        print(f"Error in _fetch_latest_full_apy: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∫—ç—à, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if full_apy_cache.get() is not None:
            print(f"Using existing cache ({len(full_apy_cache.get())} records) due to error")
            return full_apy_cache.get()
        return None

async def get_latest_full_apy(skip_cache=False):
    """Get latest APY data from database or cache"""
    log_query('get_latest_full_apy')
    
    # –ï—Å–ª–∏ –∫—ç—à –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∏ –Ω–µ –∑–∞–ø—Ä–æ—à–µ–Ω –ø—Ä–æ–ø—É—Å–∫ –∫—ç—à–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
    if full_apy_cache.is_valid() and not skip_cache:
        age = time.time() - full_apy_cache.timestamp
        cached_data = full_apy_cache.get()
        print(f"[CACHE HIT] get_latest_full_apy - using cached data from {age:.2f} seconds ago")
        return cached_data
    
    try:
        print("[CACHE MISS] get_latest_full_apy - fetching from database")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é RPC-—Ñ—É–Ω–∫—Ü–∏—é –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ —Ç–∞–±–ª–∏—Ü–µ
        data = await _fetch_latest_full_apy()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—Ä–æ—à–µ–Ω –ø—Ä–æ–ø—É—Å–∫ –∫—ç—à–∞
        if data is not None and not skip_cache:
            full_apy_cache.data = data
            full_apy_cache.timestamp = time.time()
            print(f"[CACHE UPDATE] get_latest_full_apy - cached {len(data)} records")
        
        return data
    except Exception as e:
        print(f"Error getting APY data: {e}")
        # –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—ç—à –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω —É—Å—Ç–∞—Ä–µ–ª
        if full_apy_cache.get() is not None:
            print("Returning outdated cache data after database error")
            return full_apy_cache.get()
        return None

async def _fetch_top_apy():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è top-1 APY"""
    data = await get_latest_full_apy()
    
    if not data:
        return None
    
    # Filter by TVL >= 1,000,000 and sort by APY
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )
    
    return filtered_data[0] if filtered_data else None

async def get_top_apy():
    """Get top-1 APY from cached data"""
    # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏: –ø–µ—á–∞—Ç–∞–µ–º ID —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–æ–¥—É–ª—è
    print(f"[DEBUG] get_top_apy called from module instance {id(sys.modules[__name__])}")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∫—ç—à –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
    cached_data = top_apy_cache.get()
    if cached_data is not None:
        # –î–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        cache_age = time.time() - top_apy_cache.timestamp
        print(f"[CACHE] Using cached top APY ({cache_age:.2f}s old): {cached_data.get('asset')} with APY={cached_data.get('apy')}")
        return cached_data
    
    # –ï—Å–ª–∏ –≤ –∫—ç—à–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö, –≤—ã—á–∏—Å–ª—è–µ–º –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫—ç—à–∞
    data = full_apy_cache.get()
    if data is not None:
        filtered_data = sorted(
            [item for item in data if item.get('tvl', 0) >= 1000000],
            key=lambda x: x.get('apy', 0),
            reverse=True
        )
        
        result = filtered_data[0] if filtered_data else None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        top_apy_cache.data = result
        top_apy_cache.timestamp = time.time()
        
        print(f"[CACHE] Calculated top APY from full data: {result.get('asset')} with APY={result.get('apy')}")
        return result
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏–∫–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à–µ, –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ë–î
    print("[CACHE MISS] No cached data available, fetching from database")
    result = await _fetch_top_apy()
    return result

async def _fetch_top_three_apy():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è top-3 APY"""
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # Filter by TVL >= 1,000,000 and sort by APY
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )[:3]  # Limit to three results
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
    top_three_cache.data = filtered_data
    top_three_cache.timestamp = time.time()
    print(f"[CACHE UPDATE] get_top_three_apy - cached {len(filtered_data)} results")
    
    return filtered_data

async def get_top_three_apy():
    """Get top-3 APY from cached data"""
    log_query('get_top_three_apy')
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã
    if top_three_cache.get() is not None:
        print(f"[CACHE HIT] get_top_three_apy - using cached data from {time.time() - top_three_cache.timestamp:.2f} seconds ago")
        return top_three_cache.get()
    
    print("[CACHE MISS] get_top_three_apy - calculating from full data")
    
    # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ full_apy –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
    if full_apy_cache.get() is not None:
        data = full_apy_cache.get()
        print("[CACHE REUSE] Using cached full_apy_cache for calculation")
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç, –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = await _fetch_latest_full_apy()
    
    if not data:
        return []
        
    # Filter by TVL >= 1,000,000 and sort by APY
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )[:3]  # Limit to three results
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
    top_three_cache.data = filtered_data
    top_three_cache.timestamp = time.time()
    print(f"[CACHE UPDATE] get_top_three_apy - cached {len(filtered_data)} results")
    
    return filtered_data

async def _fetch_top_ten_apy():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è top-10 APY"""
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # Filter by TVL >= 1,000,000 and sort by APY
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )[:10]  # Limit to ten results
    
    return filtered_data

async def get_top_ten_apy():
    """Get top-10 APY from cached data"""
    log_query('get_top_ten_apy')
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã
    if top_ten_cache.get() is not None:
        return top_ten_cache.get()
    
    # –ï—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç–æ–π, –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
    data = await _fetch_top_ten_apy()
    if data is not None:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑
        top_ten_cache.data = data
        top_ten_cache.timestamp = time.time()
    
    return data

async def _fetch_all_assets():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–æ–≤"""
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # Get unique assets
    all_assets = [item.get('asset') for item in data if item.get('asset')]
    unique_assets = sorted(list(set(all_assets)))
    
    return unique_assets

async def get_all_assets():
    """Get all unique asset values with caching"""
    log_query('get_all_assets')
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã
    if assets_cache.get() is not None:
        return assets_cache.get()
    
    # –ï—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç–æ–π, –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
    data = await _fetch_all_assets()
    if data is not None:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑
        assets_cache.data = data
        assets_cache.timestamp = time.time()
    
    return data

async def _fetch_all_chains():
    """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –±–ª–æ–∫—á–µ–π–Ω–æ–≤"""
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # Get unique chains
    all_chains = [item.get('chain') for item in data if item.get('chain')]
    unique_chains = sorted(list(set(all_chains)))
    
    return unique_chains

async def get_all_chains():
    """Get all unique chain values with caching"""
    log_query('get_all_chains')
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã
    if chains_cache.get() is not None:
        return chains_cache.get()
    
    # –ï—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç–æ–π, –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
    data = await _fetch_all_chains()
    if data is not None:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑
        chains_cache.data = data
        chains_cache.timestamp = time.time()
    
    return data

async def update_all_caches():
    """Update all caches with proper cache invalidation"""
    timestamp = datetime.datetime.now().isoformat()
    print(f"[{timestamp}] [CACHE] Starting update")
    
    global _cache_updating, _formatted_data_cache
    with _cache_update_lock:
        if _cache_updating:
            print(f"[{timestamp}] [CACHE] Update already in progress, skipping")
            return
        _cache_updating = True
    
    try:
        start_time = time.time()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã
        print(f"[{timestamp}] [CACHE] Fetching fresh data directly from database")
        fresh_data = await _fetch_latest_full_apy()
        
        if not fresh_data:
            print("[CACHE] Failed to get fresh data from database!")
            return
        
        # –ü–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –∫—ç—à–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        old_data = full_apy_cache.get()
        
        # –í–ê–ñ–ù–û: –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ –∫—ç—à–∏ –ø—Ä–µ–∂–¥–µ —á–µ–º —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        top_apy_cache.data = None
        top_three_cache.data = None
        top_ten_cache.data = None
        assets_cache.data = None
        chains_cache.data = None
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        _formatted_data_cache.clear()
        print("[CACHE] Formatted message cache cleared")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫—ç—à
        full_apy_cache.data = fresh_data
        full_apy_cache.timestamp = time.time()
        print(f"[CACHE] Full APY cache updated with new data - size: {len(fresh_data)}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        if old_data and len(old_data) > 0 and len(fresh_data) > 0:
            old_top = sorted([i for i in old_data if i.get('tvl', 0) >= 1000000], 
                           key=lambda x: x.get('apy', 0), reverse=True)
            new_top = sorted([i for i in fresh_data if i.get('tvl', 0) >= 1000000], 
                           key=lambda x: x.get('apy', 0), reverse=True)
            
            if old_top and new_top:
                print(f"[CACHE] Previous top APY: {old_top[0].get('asset')} on {old_top[0].get('chain')} with APY={old_top[0].get('apy')}")
                print(f"[CACHE] New top APY: {new_top[0].get('asset')} on {new_top[0].get('chain')} with APY={new_top[0].get('apy')}")
        
        # –í–ê–ñ–ù–û: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∫—ç—à–∏ —Å—Ä–∞–∑—É
        await pre_calculate_all_caches()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏–ª—Å—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–π –∫—ç—à
        if top_apy_cache.get():
            print(f"[CACHE VERIFY] Top APY after update: {top_apy_cache.get().get('asset')} with APY={top_apy_cache.get().get('apy')}")
        else:
            print("[CACHE ERROR] Top APY cache not calculated properly!")
        
        elapsed = time.time() - start_time
        print(f"[{timestamp}] [CACHE] Update completed in {elapsed:.2f} seconds")
    finally:
        with _cache_update_lock:
            _cache_updating = False

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –ø–µ—Ä–µ—Å—á–µ—Ç–∞ –∫—ç—à–µ–π
async def pre_calculate_all_caches_safe():
    """Safe version of pre_calculate_all_caches with error handling"""
    try:
        await pre_calculate_all_caches()
    except Exception as e:
        print(f"[CACHE PRECALC] Error during precalculation: {e}")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –∫—ç—à –Ω–µ –±—É–¥–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö
def check_data_changes(old_data, new_data):
    """Check if there are significant changes between old and new data"""
    if not old_data or not new_data:
        return True
    
    if len(old_data) != len(new_data):
        return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º sample –∑–∞–ø–∏—Å–µ–π –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    sample_indices = [0, min(10, len(new_data)-1), min(50, len(new_data)-1)]
    for idx in sample_indices:
        if idx < len(old_data) and idx < len(new_data):
            if (old_data[idx].get('apy') != new_data[idx].get('apy') or 
                old_data[idx].get('tvl') != new_data[idx].get('tvl')):
                return True
    
    return False

async def get_or_create_user(user_id, username):
    """Get or create a user"""
    log_query('get_or_create_user', user_id, username)
    
    try:
        # Check if the user exists
        response = supabase.table('bot_users').select('*').eq('telegram_id', str(user_id)).execute()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
        error = has_error(response)
        if error:
            print('Error checking user:', error)
            return None
        
        if response.data:
            return response.data[0]
        
        # User not found, create a new one
        response = supabase.table('bot_users').insert({
            'telegram_id': str(user_id),
            'username': username,
            'subscribed': True
        }).execute()
        
        error = has_error(response)
        if error:
            print('Error creating user:', error)
            return None
        
        return response.data[0] if response.data else None
    except Exception as e:
        print('Error in get_or_create_user:', e)
        return None

async def get_subscribed_users():
    """Get all subscribed users"""
    log_query('get_subscribed_users')
    
    try:
        response = supabase.table('bot_users').select('*').eq('subscribed', True).execute()
        
        error = has_error(response)
        if error:
            print('Error getting subscribed users:', error)
            return []
        
        return response.data
    except Exception as e:
        print('Error in get_subscribed_users:', e)
        return []

async def update_subscription_status(user_id, status):
    """Update user subscription status"""
    log_query('update_subscription_status', user_id)
    
    try:
        response = supabase.table('bot_users').update({
            'subscribed': status
        }).eq('telegram_id', str(user_id)).execute()
        
        error = has_error(response)
        if error:
            print('Error updating subscription status:', error)
            return False
        
        return True
    except Exception as e:
        print('Error in update_subscription_status:', e)
        return False

async def get_top_apy_for_asset(asset_name):
    """Get top APY for a specific asset across all chains"""
    log_query(f'get_top_apy_for_asset: {asset_name}')
    
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ –∏–º–µ–Ω–∏ –∞–∫—Ç–∏–≤–∞ –∏ TVL >= 100,000
    filtered_data = [item for item in data if item.get('asset') == asset_name and item.get('tvl', 0) >= 100000]
    
    # –ü—Ä–æ—Å—Ç–æ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –ø—É–ª—ã –ø–æ APY, –±–µ–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ —Ü–µ–ø—è–º
    sorted_data = sorted(filtered_data, key=lambda x: x.get('apy', 0), reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ 3 –ª—É—á—à–∏—Ö –ø—É–ª–∞ –≤–º–µ—Å—Ç–æ 10
    return sorted_data[:3]

async def get_user_subscription_status(user_id):
    """Get user subscription status"""
    log_query('get_user_subscription_status', user_id)
    
    try:
        response = supabase.table('bot_users').select('*').eq('telegram_id', str(user_id)).execute()
        
        error = has_error(response)
        if error:
            print('Error getting subscription status:', error)
            return None
        
        return response.data[0] if response.data else None
    except Exception as e:
        print('Error in get_user_subscription_status:', e)
        return None

async def log_user_action(action, user_id, username):
    """Log user actions to the database"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º
        is_admin = await is_user_admin(user_id)
        if is_admin:
            # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤
            return
            
        # –°–ø–∏—Å–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –¥–ª—è –∫–æ–≥–æ
        ignored_actions = ["back_to_main", "show_analytics", "notification_sent"]
        if action in ignored_actions:
            # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            return
            
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –æ–±—ã—á–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        response = supabase.table('user_actions').insert({
            'user_id': str(user_id),
            'username': username,
            'action': action
        }).execute()
        
        error = has_error(response)
        if error:
            print('Error logging action to database:', error)
    except Exception as e:
        print('Error in log_user_action:', e)

async def is_user_admin(user_id):
    """Check if the user is an administrator"""
    try:
        response = supabase.table('bot_users').select('is_admin').eq('telegram_id', str(user_id)).execute()
        
        error = has_error(response)
        if error:
            print('Error checking admin status:', error)
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—É—Å—Ç—ã –∏ user –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ admin
        return response.data and response.data[0].get('is_admin', False)
    except Exception as e:
        print('Error in is_user_admin:', e)
        return False

async def get_analytics():
    """Get analytics data for admin dashboard"""
    try:
        # Get time boundaries
        now = datetime.datetime.now()
        today = now.replace(hour=0, minute=0, second=0, microsecond=0)
        
        one_week_ago = now - datetime.timedelta(days=7)
        one_month_ago = now - datetime.timedelta(days=30)
        
        # New users today
        today_users_response = supabase.table('bot_users').select('telegram_id').gte(
            'created_at', today.isoformat()
        ).execute()
        
        # New users this week
        week_users_response = supabase.table('bot_users').select('telegram_id').gte(
            'created_at', one_week_ago.isoformat()
        ).execute()
        
        # New users this month
        month_users_response = supabase.table('bot_users').select('telegram_id').gte(
            'created_at', one_month_ago.isoformat()
        ).execute()
        
        # Total users
        total_users_response = supabase.table('bot_users').select('telegram_id').execute()
        
        # Get admin user IDs to exclude from analytics
        admin_users_response = supabase.table('bot_users').select('telegram_id').eq('is_admin', True).execute()
        admin_user_ids = [admin.get('telegram_id') for admin in admin_users_response.data] if admin_users_response.data else []
        
        # Action statistics - using RPC
        actions_response = supabase.rpc('count_actions_by_type', {}).execute()
        
        # Today's action statistics - using RPC
        today_actions_response = supabase.rpc('count_todays_actions_by_type', {
            'today_date': today.isoformat()
        }).execute()
        
        # Filter out admin actions from statistics
        actions = actions_response.data if actions_response.data else []
        today_actions = today_actions_response.data if today_actions_response.data else []
        
        # Count users excluding any errors
        today_users_count = len(today_users_response.data) if not has_error(today_users_response) else 0
        week_users_count = len(week_users_response.data) if not has_error(week_users_response) else 0
        month_users_count = len(month_users_response.data) if not has_error(month_users_response) else 0
        total_users_count = len(total_users_response.data) if not has_error(total_users_response) else 0
        
        return {
            'new_users': {
                'today': today_users_count,
                'week': week_users_count,
                'month': month_users_count,
                'total': total_users_count
            },
            'actions': actions,
            'today_actions': today_actions
        }
    except Exception as e:
        print('Error generating analytics:', e)
        return None

async def get_top_apy_for_chain(chain_name):
    """Get top APY for a specific chain across all assets"""
    log_query(f'get_top_apy_for_chain: {chain_name}')
    
    data = await get_latest_full_apy()
    
    if not data:
        return []
    
    # –û—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    all_chains = set(item.get('chain') for item in data if item.get('chain'))
    print(f"[CHAIN] Looking for chain '{chain_name}' among available chains: {all_chains}")
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω–æ–µ —Ä–µ–≥–∏—Å—Ç—Ä–æ-–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ë–ï–ó —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ TVL
    filtered_data = [item for item in data if item.get('chain') and 
                    item.get('chain').lower() == chain_name.lower()]
    
    # –ï—Å–ª–∏ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if not filtered_data:
        print(f"[CHAIN] No exact match for chain '{chain_name}', trying partial match")
        
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ü–µ–ø—å –∫–∞–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫—É (—Å —É–¥–∞–ª–µ–Ω–∏–µ–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–π –¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏)
        filtered_data = [item for item in data if item.get('chain') and 
                     (chain_name.lower().replace('_', '') in item.get('chain').lower().replace('_', '') or
                      item.get('chain').lower().replace('_', '') in chain_name.lower().replace('_', ''))]
    
    # –ü—Ä–æ—Å—Ç–æ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –ø—É–ª—ã –ø–æ APY, –±–µ–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–∫—Ç–∏–≤–∞–º –∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ TVL
    sorted_data = sorted(filtered_data, key=lambda x: x.get('apy', 0), reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ 3 –ª—É—á—à–∏—Ö –ø—É–ª–∞
    if sorted_data:
        print(f"[CHAIN] Found {len(sorted_data)} pools for chain '{chain_name}'")
    else:
        print(f"[CHAIN] No pools found for chain '{chain_name}' after matching")
    
    return sorted_data[:3]

async def pre_calculate_all_caches():
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∫—ç—à–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ full_apy_cache"""
    if full_apy_cache.get() is None:
        print("[CACHE PRECALC] No full APY data available, skipping precalculation")
        return False
        
    print("[CACHE PRECALC] Starting precalculation of all caches")
    start_time = time.time()
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫—ç—à–∞ –æ–¥–∏–Ω —Ä–∞–∑
    data = full_apy_cache.get()
    current_time = time.time()
    
    # –†–∞—Å—á–µ—Ç –¥–ª—è top APY (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ TVL)
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )
    
    print(f"[CACHE PRECALC] Found {len(filtered_data)} pools with TVL >= 1M")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_apy_cache
    top_apy_cache.data = filtered_data[0] if filtered_data else None
    top_apy_cache.timestamp = current_time
    
    if filtered_data:
        print(f"[CACHE PRECALC] Top APY: {filtered_data[0].get('asset')} on {filtered_data[0].get('chain')} with APY={filtered_data[0].get('apy')}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_three_cache
    top_three_cache.data = filtered_data[:3]
    top_three_cache.timestamp = current_time
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_ten_cache
    top_ten_cache.data = filtered_data[:10]
    top_ten_cache.timestamp = current_time
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤—ã –∏ —Ü–µ–ø–æ—á–∫–∏
    all_assets = sorted(list(set(item.get('asset') for item in data if item.get('asset'))))
    assets_cache.data = all_assets
    assets_cache.timestamp = current_time
    
    all_chains = sorted(list(set(item.get('chain') for item in data if item.get('chain'))))
    chains_cache.data = all_chains
    chains_cache.timestamp = current_time
    
    end_time = time.time()
    print(f"[CACHE PRECALC] All caches precalculated in {end_time - start_time:.2f} seconds")
    return True

# –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π
async def force_refresh_all_caches():
    """Force refresh all caches by directly fetching from database"""
    print("[FORCE REFRESH] Starting forced refresh of all caches")
    
    try:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        global _cache_updating, _formatted_data_cache
        with _cache_update_lock:
            if _cache_updating:
                print("[FORCE REFRESH] Update already in progress, skipping")
                return False
            _cache_updating = True
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ë–î
        print("[FORCE REFRESH] Calling database for fresh data")
        fresh_data = await _fetch_latest_full_apy()
        
        if not fresh_data:
            print("[FORCE REFRESH] Failed to get data from database")
            return False
        
        # –ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ –∫—ç—à–∏
        print("[FORCE REFRESH] Clearing all caches")
        full_apy_cache.data = None
        top_apy_cache.data = None
        top_three_cache.data = None
        top_ten_cache.data = None
        assets_cache.data = None
        chains_cache.data = None
        _formatted_data_cache.clear()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫—ç—à —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        full_apy_cache.data = fresh_data
        full_apy_cache.timestamp = time.time()
        print(f"[FORCE REFRESH] Primary cache updated with {len(fresh_data)} records")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –≤—Å–µ—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –∫—ç—à–µ–π
        await _force_calculate_all_caches()
        
        print("[FORCE REFRESH] All caches completely refreshed with new data")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —Ç–æ–ø APY –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏–ª—Å—è
        if top_apy_cache.get():
            print(f"[FORCE REFRESH] Verified top APY: {top_apy_cache.get().get('asset')} with {top_apy_cache.get().get('apy')}")
        else:
            print("[FORCE REFRESH] Warning: top_apy_cache is still empty after refresh!")
        
        return True
    except Exception as e:
        print(f"[FORCE REFRESH] Error during force refresh: {e}")
        return False
    finally:
        with _cache_update_lock:
            _cache_updating = False

# –û—Ç–¥–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –∫—ç—à–µ–π
async def _force_calculate_all_caches():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç –≤—Å–µ—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö –∫—ç—à–µ–π —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    print("[FORCE CALC] Starting forced calculation of all derivative caches")
    start_time = time.time()
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫—ç—à–∞
    data = full_apy_cache.get()
    if not data:
        print("[FORCE CALC] Error: No data in full_apy_cache!")
        return False
    
    # –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –¥–ª—è –≤—Å–µ—Ö –∫—ç—à–µ–π (–¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏)
    current_time = time.time()
    
    # –†–∞—Å—á–µ—Ç –¥–ª—è top APY
    filtered_data = sorted(
        [item for item in data if item.get('tvl', 0) >= 1000000],
        key=lambda x: x.get('apy', 0),
        reverse=True
    )
    
    print(f"[FORCE CALC] Found {len(filtered_data)} pools with TVL >= 1M")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_apy_cache (–ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ)
    if filtered_data:
        top_pool = filtered_data[0]
        print(f"[FORCE CALC] Setting top pool: {top_pool.get('asset')} on {top_pool.get('chain')} with APY={top_pool.get('apy')}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à
        top_apy_cache.data = top_pool
        top_apy_cache.timestamp = current_time
    else:
        top_apy_cache.data = None
        print("[FORCE CALC] Warning: No pools with sufficient TVL")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_three_cache
    top_three = filtered_data[:3]
    top_three_cache.data = top_three
    top_three_cache.timestamp = current_time
    
    # –û–±–Ω–æ–≤–ª—è–µ–º top_ten_cache
    top_ten = filtered_data[:10]
    top_ten_cache.data = top_ten
    top_ten_cache.timestamp = current_time
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫—ç—à–∏
    unique_assets = sorted(list(set(item.get('asset') for item in data if item.get('asset'))))
    assets_cache.data = unique_assets
    assets_cache.timestamp = current_time
    
    unique_chains = sorted(list(set(item.get('chain') for item in data if item.get('chain'))))
    chains_cache.data = unique_chains
    chains_cache.timestamp = current_time
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    print(f"[FORCE CALC] Verification - Top APY: {top_pool.get('asset') if 'top_pool' in locals() else 'None'} with APY={top_pool.get('apy') if 'top_pool' in locals() else 'N/A'}")
    
    end_time = time.time()
    print(f"[FORCE CALC] All caches forcefully calculated in {end_time - start_time:.2f} seconds")
    return True

# –ó–∞–≤–µ—Ä—à–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é format_top_apy_data
def format_top_apy_data(data, position):
    """Format APY data for display with ranking (optimized)"""
    if not data:
        return "No data available"
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–ª-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∫–ª—é—á –∫—ç—à–∞, –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –æ—Ç –ø–æ–∑–∏—Ü–∏–∏
    cache_key = f"{data.get('pool_id', '')}"
    if cache_key in _formatted_data_cache:
        formatted_text = _formatted_data_cache[cache_key]
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ emoji –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–∑–∏—Ü–∏–∏
        position_emoji = 'ü•á' if position == 1 else 'ü•à' if position == 2 else 'ü•â' if position == 3 else 'üèÖ'
        return formatted_text.replace("POSITION_EMOJI", position_emoji)
    
    # Extract protocol name from pool_id
    pool_id = data.get('pool_id', '')
    protocol_parts = pool_id.split('_')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–∞–∫ –º–∏–Ω–∏–º—É–º 3 —á–∞—Å—Ç–∏ –≤ pool_id
    if len(protocol_parts) >= 3:
        protocol = '_'.join(protocol_parts[2:])
    else:
        protocol = protocol_parts[0] if protocol_parts else ''
    
    # Format TVL
    tvl = data.get('tvl', 0)
    if tvl >= 1000000:
        tvl_formatted = f"${tvl / 1000000:.1f}M"
    elif tvl >= 1000:
        tvl_formatted = f"${tvl / 1000:.1f}K"
    else:
        tvl_formatted = f"${tvl:.0f}"
    
    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ APY –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ None
    apy = data.get('apy')
    apy_base = data.get('apy_base')
    apy_reward = data.get('apy_reward')
    apy_mean_30d = data.get('apy_mean_30d')
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –∑–Ω–∞—á–µ–Ω–∏–π APY
    apy_total = f"{apy:.2f}%" if apy is not None else 'N/A'
    apy_base_fmt = f"{apy_base:.2f}%" if apy_base is not None else 'N/A'
    apy_reward_fmt = f"{apy_reward:.2f}%" if apy_reward is not None else 'N/A'
    apy_mean_30d_fmt = f"{apy_mean_30d:.2f}%" if apy_mean_30d is not None else 'N/A'
    
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
    protocol_safe = protocol.replace('_', '\\_').replace('*', '\\*').replace('[', '\\[').replace(']', '\\]')
    
    # Add link to pool site, if available
    site_link = f"   ‚îú [Pool Site]({data.get('site_url')})\n" if data.get('site_url') else ''
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω —Å –∑–∞–º–µ–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏ –ø–æ–∑–∂–µ
    try:
        result = (
            f"POSITION_EMOJI *{data.get('asset')}* on *{data.get('chain')}*\n"
            f"   ‚îå Protocol: *{protocol_safe}*\n"
            f"{site_link}"
            f"   ‚îú APY Total: *{apy_total}*\n"
            f"   ‚îú APY Base: {apy_base_fmt}\n"
            f"   ‚îú APY Reward: {apy_reward_fmt}\n"
            f"   ‚îú Avg APY 30d: {apy_mean_30d_fmt}\n"
            f"   ‚îî TVL: {tvl_formatted}"
        )
    except Exception as e:
        print(f"[FORMAT ERROR] Error formatting pool data: {e}")
        # –£–ø—Ä–æ—â—ë–Ω–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        result = (
            f"POSITION_EMOJI Asset: {data.get('asset')} on {data.get('chain')}\n"
            f"Protocol: {protocol}\n"
            f"APY: {apy_total}\n"
            f"TVL: {tvl_formatted}"
        )
    
    # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    _formatted_data_cache[cache_key] = result
    
    # –ó–∞–º–µ–Ω—è–µ–º —ç–º–æ–¥–∑–∏ –ø–æ–∑–∏—Ü–∏–∏ –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
    position_emoji = 'ü•á' if position == 1 else 'ü•à' if position == 2 else 'ü•â' if position == 3 else 'üèÖ'
    return result.replace("POSITION_EMOJI", position_emoji)

async def update_format_cache(key, value):
    """Safely update format cache with lock"""
    async with _format_cache_lock:
        _formatted_data_cache[key] = value 

def get_latest_top_apy_value():
    """Get the current value of the top APY from cache"""
    data = top_apy_cache.get()
    if data:
        return data.get('apy')
    return None 